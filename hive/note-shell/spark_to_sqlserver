spark-shell --driver-class-path /home/hduser/sqljdbc42.jar 

////////////////////////////////////////////////////////

// Create the SQLContext first from the existing Spark Context
val sqlContext = new org.apache.spark.sql.SQLContext(sc)

// Construct JDBC URL
val jdbcSqlConnStr = "jdbc:sqlserver://192.168.0.9;databaseName=eHRM_demoP;user=sa;password=Ab123456;"

// Define database table to load into DataFrame
val jdbcDbTable = "PERIODS"

// Load DataFrame with JDBC data-source properties

val jdbcDF = sqlContext.read.format("jdbc").options( Map("url" -> jdbcSqlConnStr, "dbtable" -> jdbcDbTable)).load()

// Displays the content of the DataFrame to stdout ...first 10 rows
jdbcDF.show(10)

// Register the DataFrame as a table
jdbcDF.registerTempTable("Sales")

// SQL statement can be run by using the sql methods provided by sqlContext.
val saleInvoices = sqlContext.sql("SELECT InvoiceID, Quantity, UnitPrice, TaxAmount, ExtendedPrice FROM Sales WHERE Description = 'White chocolate moon rocks 250g'")

// Displays the content of the DataFrame
saleInvoices.show()

//SQL statement - Sum of ExtendedPrice for 'White chocolate moon rocks 250g' product 
val sumInvoices = sqlContext.sql("SELECT SUM(ExtendedPrice) AS TotalSales FROM Sales WHERE Description = 'White chocolate moon rocks 250g'")

// Displays the content of the DataFrame
sumInvoices.show()


////////////////////////////////////////////

sqlContext.read.jdbc("jdbc:sqlserver://192.168.0.9;databaseName=moneycorp;integratedSecurity=true;", "TABLE_NAME", "id", 1, 100000, 1000, new java.util.Properties)

val jdbcDF2 = spark.read
  .format("jdbc")
  .option("url", "jdbc:sqlserver://192.168.0.9;databaseName=eHRM_demoP;")
  .option("dbtable", "INCOMES")
  .option("user", "sa")
  .option("password", "Ab123456")
  .load()

val jdbcDF2 = spark.read.format("jdbc").option("url", "jdbc:sqlserver://192.168.0.9;databaseName=eHRM_demoP;").option("dbtable", "INCOMES").option("user", "sa").option("password", "Ab123456").load()

////////////////////////////////////////


val jdbcDF3 = spark.read.format("jdbc").option("url", "jdbc:sqlserver://192.168.0.9;databaseName=eHRM_demoP;user=sa;password=Ab123456;").option("dbtable", "TIME_SHEETS").load()
jdbcDF3.show(10)
